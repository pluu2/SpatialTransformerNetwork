{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from jax import grad,jit,vmap\n",
    "#import tensorflow as tf\n",
    "import matplotlib.pyplot as py\n",
    "#tf.config.experimental.set_visible_devices([], \"GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1= np.ones((28,28)) *0.5\n",
    "\n",
    "for i in range(2,22): \n",
    "  for j in range (2,22): \n",
    "    image1[i][j]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f873d204730>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "py.imshow(image1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target= np.zeros((28,28))\n",
    "for i in range(2,22): \n",
    "  for j in range (2,22): \n",
    "    target[i][j]=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f873d16bd00>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAKgUlEQVR4nO3dT4ic933H8fentiwTJQWpaYXimCYNpmAKVcqiFmJKipvE8UXOJUSHoIJhc4ghgRxq0kN9NKVJ6KEElFpELalDITHWwTRRRcAEivHaqLZst5VrFCJVlhp8iFOoLDvfHvZx2Ni72vXMM3/a7/sFy8w8z+w+Xwa/PTPPjP1LVSHp/79fWfQAkubD2KUmjF1qwtilJoxdauLGeR7spuyum9kzz0NKrfwP/81rdTWb7Zsq9iR3AX8F3AD8TVU9eL3738wefj93TnNISdfxRJ3ect/EL+OT3AD8NfBJ4HbgSJLbJ/17kmZrmvfsh4AXq+qlqnoN+DZweJyxJI1tmthvAX684faFYdsvSbKaZC3J2jWuTnE4SdOY+dn4qjpWVStVtbKL3bM+nKQtTBP7ReDWDbffP2yTtISmif1J4LYkH0xyE/AZ4OQ4Y0ka28QfvVXV60nuA77H+kdvx6vqudEmkzSqqT5nr6rHgMdGmkXSDPl1WakJY5eaMHapCWOXmjB2qQljl5qY63/PPq3v/eeZRY+gJj7xvoOLHmF0PrNLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNTPX/jU9yHngVeAN4vapWxhhK0vjGWCTij6rqJyP8HUkz5Mt4qYlpYy/g+0meSrK62R2SrCZZS7J2jatTHk7SpKZ9GX9HVV1M8hvAqST/WlWPb7xDVR0DjgH8avbVlMeTNKGpntmr6uJweQV4BDg0xlCSxjdx7En2JHnPm9eBjwNnxxpM0rimeRm/H3gkyZt/5++r6h9HmUrS6CaOvapeAn53xFkkzZAfvUlNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9TEtrEnOZ7kSpKzG7btS3Iqybnhcu9sx5Q0rZ08s38TuOst2+4HTlfVbcDp4bakJbZt7FX1OPDKWzYfBk4M108A94w7lqSx3Tjh7+2vqkvD9ZeB/VvdMckqsApwM++a8HCSpjX1CbqqKqCus/9YVa1U1coudk97OEkTmjT2y0kOAAyXV8YbSdIsTBr7SeDocP0o8Og440ialZ189PYw8M/Abye5kORe4EHgY0nOAX883Ja0xLY9QVdVR7bYdefIs0iaIb9BJzVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhM7WZ/9eJIrSc5u2PZAkotJzgw/d892TEnT2skz+zeBuzbZ/rWqOjj8PDbuWJLGtm3sVfU48MocZpE0Q9O8Z78vyTPDy/y9W90pyWqStSRr17g6xeEkTWPS2L8OfAg4CFwCvrLVHavqWFWtVNXKLnZPeDhJ05oo9qq6XFVvVNXPgW8Ah8YdS9LYJoo9yYENNz8FnN3qvpKWw43b3SHJw8BHgfcmuQD8OfDRJAeBAs4Dn5vdiJLGsG3sVXVkk80PzWAWSTPkN+ikJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qYtvYk9ya5AdJnk/yXJIvDNv3JTmV5NxwuXf240qa1E6e2V8HvlRVtwN/AHw+ye3A/cDpqroNOD3clrSkto29qi5V1dPD9VeBF4BbgMPAieFuJ4B7ZjSjpBHc+E7unOQDwIeBJ4D9VXVp2PUysH+L31kFVgFu5l0TDyppOjs+QZfk3cB3gC9W1U837quqAmqz36uqY1W1UlUru9g91bCSJrej2JPsYj30b1XVd4fNl5McGPYfAK7MZkRJY9jJ2fgADwEvVNVXN+w6CRwdrh8FHh1/PElj2cl79o8AnwWeTXJm2PZl4EHgH5LcC/wI+PRMJpQ0im1jr6ofAtli953jjiNpVvwGndSEsUtNGLvUhLFLTRi71MQ7+rrson3ifQcXPYL0f5bP7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhM7WZ/91iQ/SPJ8kueSfGHY/kCSi0nODD93z35cSZPaySIRrwNfqqqnk7wHeCrJqWHf16rqL2c3nqSx7GR99kvApeH6q0leAG6Z9WCSxvWO3rMn+QDwYeCJYdN9SZ5JcjzJ3i1+ZzXJWpK1a1ydblpJE9tx7EneDXwH+GJV/RT4OvAh4CDrz/xf2ez3qupYVa1U1coudk8/saSJ7Cj2JLtYD/1bVfVdgKq6XFVvVNXPgW8Ah2Y3pqRp7eRsfICHgBeq6qsbth/YcLdPAWfHH0/SWHZyNv4jwGeBZ5OcGbZ9GTiS5CBQwHngczOYT9JIdnI2/odANtn12PjjSJoVv0EnNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhOpqvkdLPkv4EcbNr0X+MncBnhnlnW2ZZ0LnG1SY872m1X165vtmGvsbzt4slZVKwsb4DqWdbZlnQucbVLzms2X8VITxi41sejYjy34+NezrLMt61zgbJOay2wLfc8uaX4W/cwuaU6MXWpiIbEnuSvJvyV5Mcn9i5hhK0nOJ3l2WIZ6bcGzHE9yJcnZDdv2JTmV5NxwuekaewuabSmW8b7OMuMLfewWvfz53N+zJ7kB+HfgY8AF4EngSFU9P9dBtpDkPLBSVQv/AkaSPwR+BvxtVf3OsO0vgFeq6sHhX5R7q+pPl2S2B4CfLXoZ72G1ogMblxkH7gH+hAU+dteZ69PM4XFbxDP7IeDFqnqpql4Dvg0cXsAcS6+qHgdeecvmw8CJ4foJ1v9hmbstZlsKVXWpqp4err8KvLnM+EIfu+vMNReLiP0W4Mcbbl9gudZ7L+D7SZ5KsrroYTaxv6ouDddfBvYvcphNbLuM9zy9ZZnxpXnsJln+fFqeoHu7O6rq94BPAp8fXq4upVp/D7ZMn53uaBnvedlkmfFfWORjN+ny59NaROwXgVs33H7/sG0pVNXF4fIK8AjLtxT15TdX0B0uryx4nl9YpmW8N1tmnCV47Ba5/PkiYn8SuC3JB5PcBHwGOLmAOd4myZ7hxAlJ9gAfZ/mWoj4JHB2uHwUeXeAsv2RZlvHeaplxFvzYLXz586qa+w9wN+tn5P8D+LNFzLDFXL8F/Mvw89yiZwMeZv1l3TXWz23cC/wacBo4B/wTsG+JZvs74FngGdbDOrCg2e5g/SX6M8CZ4efuRT9215lrLo+bX5eVmvAEndSEsUtNGLvUhLFLTRi71ISxS00Yu9TE/wIA1j/Cjqi4xQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "py.imshow(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This needs to be changed to store x,y, I will store the third diemsnion later. \n",
    "#each mask contains an x,y coordinate which is what the affine transformation works on.\n",
    "mask=np.zeros((784,2))\n",
    "i = 0\n",
    "for y in range(28):\n",
    "    for x in range(28): \n",
    "      mask[i][0]=y#-14\n",
    "      mask[i][1]=x#-14\n",
    "      #mask[i][2]=1\n",
    "      i+=1\n",
    "\n",
    "affine_matrix = np.array([[1,0],\n",
    "                [0,1]])\n",
    "\n",
    "\n",
    "#The transformation is performed on this mask, and then the sampling occurs on the actual 'feature map'\n",
    "#I believe this is what happens in Jaderberg et al.? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_mask = np.dot (mask[2],affine_matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 784 into shape (784,2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a40f9045dba1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 784 into shape (784,2)"
     ]
    }
   ],
   "source": [
    "feature=image1.reshape(784,2) \n",
    "target=target.reshape(784,2)\n",
    "kernel = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network \n",
    "Sampling has to be something like\n",
    "\n",
    "$ V^C_i = \\sum^H_n\\sum^W_m U^C_{nm} max (0,1-|x^s_i-m|)max(0,1-|y^s_i-n|)$\n",
    "\n",
    "which has a very basic form of: \n",
    "$V = U \\tau F(x,y) $ with $U$ being the feature map\n",
    "\n",
    "$F(x,y)$ is the sampling, $U$ is the original feature map, and $\\tau$ is the affine matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_map will store the actual color value of the image\n",
    "#mask will store the coordinates, which will be used for affine trasnformation. \n",
    "#affine_matrix is the actual transformation matrix. \n",
    "#The network decides if the pixel will have the affine trasnformation applied. \n",
    "def sampling_network(feature_map,parameters,bias):  #parameters will be 1,1  \n",
    "    \n",
    "    #The feature map then enters a sampling network, based on pixel value. \n",
    "    layer1=jnp.dot(feature_map,parameters[0].T) + bias[0]  #(32,1) \n",
    "    layer1=jax.nn.relu(layer1) \n",
    "    layer2=jnp.dot(layer1,parameters[1].T)+bias[1]  #(1,32)\n",
    "    layer2=jax.nn.sigmoid(layer2) \n",
    "    return layer2\n",
    "#This takes the sample output of the sampling_network (0 or 1) and \n",
    "#transform and outputs the final image in the form of (784,2)\n",
    "def transformation_network (affine_matrix,coordinates,feature_map,parameters,bias): \n",
    "    #This is basically saying \"perform the affine matrix, and apply it whether or not the sampling _networ\n",
    "    #says to do it. \"\n",
    "    output= np.dot (cordinates,affine_matrix.T) * sampling_network(feature_map,parameters,bias)\n",
    "    return output\n",
    "\n",
    "\n",
    "vmap_forward= vmap(forward, in_axes =(0,None,None))\n",
    "\n",
    "def MSE_error(pixels_,target,parameters,bias): \n",
    "  pred = forward(pixels_,parameters,bias) \n",
    "  error = 0.5*(target-pred)**2 #sum over image\n",
    "  return error[0]\n",
    "\n",
    "gradient=grad(MSE_error, argnums=(2,3))\n",
    "\n",
    "def update_params(dparams,dbias,parameters,bias,lr=0.001): \n",
    "  for i in range(len(dparams)):\n",
    "    parameters[i]=parameters[i] - (lr*dparams[i])\n",
    "    bias[i] = bias[i] - (lr*dbias[i]) \n",
    "  return [parameters,bias]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
